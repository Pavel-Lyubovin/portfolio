{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация алгоритма TF-IDF\n",
    "\n",
    "https://ru.wikipedia.org/wiki/TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def tf_idf(corpus: List[List[str]]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Реализация TF-IDF\n",
    "    :param corpus: List[List[int]] - текстовый корпус, который надо закодировать\n",
    "        List первого уровня - документ\n",
    "        List второго уровня - токены\n",
    "    :return: np.ndarray - матрица TF-IDF: строки - документ, столбцы - токены\n",
    "    \"\"\"\n",
    "    vacabulary = {}\n",
    "    tfs = []\n",
    "    for doc in corpus:\n",
    "        c = Counter(doc)\n",
    "        n_tokens_in_doc = len(doc)\n",
    "        tf = {t: n / n_tokens_in_doc for t, n in c.items()}\n",
    "        tfs.append(tf)\n",
    "\n",
    "        for token in tf.keys():\n",
    "            vacabulary[token] = vacabulary.get(token, 0) + 1\n",
    "    \n",
    "    matrix = []\n",
    "    for i in range(len(corpus)):\n",
    "        row = []\n",
    "        for token in vacabulary.keys():\n",
    "            idf = np.log10(len(corpus) / vacabulary[token])\n",
    "            el = tfs[i][token] * idf if token in tfs[i].keys() else 0\n",
    "            row.append(el)\n",
    "        matrix.append(row)\n",
    "\n",
    "    return np.array(matrix), vacabulary, tfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15904042, 0.15904042, 0.05869709, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.11739417, 0.05869709, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.11739417, 0.15904042]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    ['дает', 'корова', 'молоко'],\n",
    "    ['молоко', 'молоко', 'кефир'],\n",
    "    ['облако', 'кефир', 'кефир'],\n",
    "\n",
    "]\n",
    "\n",
    "m, vac, tfs = tf_idf(corpus)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'дает': 1, 'корова': 1, 'молоко': 2, 'кефир': 2, 'облако': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'дает': 0.3333333333333333,\n",
       "  'корова': 0.3333333333333333,\n",
       "  'молоко': 0.3333333333333333},\n",
       " {'молоко': 0.6666666666666666, 'кефир': 0.3333333333333333},\n",
       " {'облако': 0.3333333333333333, 'кефир': 0.6666666666666666}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Варант №2\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def tf_idf_2(corpus: List[List[str]]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Реализация TF-IDF\n",
    "    :param corpus: List[List[int]] - текстовый корпус, который надо закодировать\n",
    "        List первого уровня - документ\n",
    "        List второго уровня - токены\n",
    "    :return: np.ndarray - матрица TF-IDF: строки - документ, столбцы - токены\n",
    "    \"\"\"\n",
    "    vacabulary = {}\n",
    "    tfs = []\n",
    "    for doc in corpus:\n",
    "        c = Counter(doc)\n",
    "        n_tokens_in_doc = len(doc)\n",
    "        tf = {t: n / n_tokens_in_doc for t, n in c.items()}\n",
    "        tfs.append(tf)\n",
    "\n",
    "        for token in tf.keys():\n",
    "            vacabulary[token] = vacabulary.get(token, 0) + 1\n",
    "    \n",
    "    matrix = np.zeros((len(corpus), len(vacabulary)))\n",
    "    idx_token = dict(zip(vacabulary.keys(), range(len(vacabulary))))\n",
    "    num_token = list(vacabulary.keys())\n",
    "\n",
    "    for i, tf in enumerate(tfs):\n",
    "        for token, value in tf.items():\n",
    "            matrix[i, idx_token[token]] = value\n",
    "    \n",
    "    for i in range(len(vacabulary)):\n",
    "        matrix[:, i] *= np.log10(len(corpus) / vacabulary[num_token[i]])\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15904042, 0.15904042, 0.05869709, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.11739417, 0.05869709, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.11739417, 0.15904042]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    ['дает', 'корова', 'молоко'],\n",
    "    ['молоко', 'молоко', 'кефир'],\n",
    "    ['облако', 'кефир', 'кефир'],\n",
    "\n",
    "]\n",
    "\n",
    "tf_idf_2(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.03201659, 0.0160083 , 0.0160083 , 0.03201659,\n",
       "        0.0160083 , 0.04337466, 0.04337466, 0.04337466, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.0195657 , 0.0195657 , 0.0195657 , 0.0195657 ,\n",
       "        0.0195657 , 0.        , 0.        , 0.        , 0.05301347,\n",
       "        0.05301347, 0.05301347, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.11928031, 0.11928031]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    ['data', 'science', 'is', 'one', 'of', 'the', 'most', 'important', 'fields', 'of', 'science'],\n",
    "    ['this', 'is', 'one', 'of', 'the', 'best', 'data', 'science', 'courses'],\n",
    "    ['data', 'scientists', 'analyze', 'data'],\n",
    "]\n",
    "\n",
    "tf_idf_2(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнить с:\n",
    "https://www.sefidian.com/2022/07/28/understanding-tf-idf-with-python-example/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the corpus: 14\n",
      "The words in the corpus: \n",
      " {'fields', 'of', 'best', 'most', 'courses', 'important', 'the', 'is', 'scientists', 'one', 'data', 'this', 'science', 'analyze'}\n",
      "IDF of: \n",
      "         fields: 0.47712125471966244\n",
      "             of: 0.17609125905568124\n",
      "           best: 0.47712125471966244\n",
      "           most: 0.47712125471966244\n",
      "        courses: 0.47712125471966244\n",
      "      important: 0.47712125471966244\n",
      "            the: 0.17609125905568124\n",
      "             is: 0.17609125905568124\n",
      "     scientists: 0.47712125471966244\n",
      "            one: 0.17609125905568124\n",
      "           data:        0.0\n",
      "           this: 0.47712125471966244\n",
      "        science: 0.17609125905568124\n",
      "        analyze: 0.47712125471966244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fields</th>\n",
       "      <th>of</th>\n",
       "      <th>best</th>\n",
       "      <th>most</th>\n",
       "      <th>courses</th>\n",
       "      <th>important</th>\n",
       "      <th>the</th>\n",
       "      <th>is</th>\n",
       "      <th>scientists</th>\n",
       "      <th>one</th>\n",
       "      <th>data</th>\n",
       "      <th>this</th>\n",
       "      <th>science</th>\n",
       "      <th>analyze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fields        of      best      most   courses  important       the  \\\n",
       "0  0.043375  0.032017  0.000000  0.043375  0.000000   0.043375  0.016008   \n",
       "1  0.000000  0.019566  0.053013  0.000000  0.053013   0.000000  0.019566   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "\n",
       "         is  scientists       one  data      this   science  analyze  \n",
       "0  0.016008     0.00000  0.016008   0.0  0.000000  0.032017  0.00000  \n",
       "1  0.019566     0.00000  0.019566   0.0  0.053013  0.019566  0.00000  \n",
       "2  0.000000     0.11928  0.000000   0.0  0.000000  0.000000  0.11928  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = ['data science is one of the most important fields of science',\n",
    "          'this is one of the best data science courses',\n",
    "          'data scientists analyze data' ]\n",
    "\n",
    "words_set = set()\n",
    " \n",
    "for doc in  corpus:\n",
    "    words = doc.split(' ')\n",
    "    words_set = words_set.union(set(words))\n",
    "     \n",
    "print('Number of words in the corpus:',len(words_set))\n",
    "print('The words in the corpus: \\n', words_set)\n",
    "\n",
    "n_docs = len(corpus)         #·Number of documents in the corpus\n",
    "n_words_set = len(words_set) #·Number of unique words in the\n",
    " \n",
    "df_tf = pd.DataFrame(np.zeros((n_docs, n_words_set)), columns=list(words_set))\n",
    " \n",
    "# Compute Term Frequency (TF)\n",
    "for i in range(n_docs):\n",
    "    words = corpus[i].split(' ') # Words in the document\n",
    "    for w in words:\n",
    "        df_tf[w][i] = df_tf[w][i] + (1 / len(words))\n",
    "\n",
    "print(\"IDF of: \")\n",
    " \n",
    "idf = {}\n",
    " \n",
    "for w in words_set:\n",
    "    k = 0    # number of documents in the corpus that contain this word\n",
    "     \n",
    "    for i in range(n_docs):\n",
    "        if w in corpus[i].split():\n",
    "            k += 1\n",
    "             \n",
    "    idf[w] =  np.log10(n_docs / k)\n",
    "     \n",
    "    print(f'{w:>15}: {idf[w]:>10}' )\n",
    "\n",
    "    df_tf_idf = df_tf.copy()\n",
    " \n",
    "for w in words_set:\n",
    "    for i in range(n_docs):\n",
    "        df_tf_idf[w][i] = df_tf[w][i] * idf[w]\n",
    "         \n",
    "df_tf_idf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
