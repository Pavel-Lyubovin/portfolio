{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce276989",
   "metadata": {},
   "source": [
    "Тема: Разбор методов построения uplift-моделей\n",
    "\n",
    "Видео лекции:  \n",
    "https://www.youtube.com/watch?v=ofP2JjPhmqg\n",
    "\n",
    "Видео семинара:  \n",
    "нет\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0964fabc",
   "metadata": {},
   "source": [
    "## Домашнее задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f7c4b",
   "metadata": {},
   "source": [
    "Необходимо реализовать алгоритм построения uplift-дерева с критерием разбиения DeltaDeltaP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a8fb3",
   "metadata": {},
   "source": [
    "Определим оценку uplift в вершине дерева.  \n",
    "Она будет равна разности средних значений Y в целевой группе и контрольной:\n",
    "$$\\tau_{node} = \\frac{\\Sigma_{i \\in node}Y_i T_i}{\\Sigma_{i \\in node}T_i} - \\frac{\\Sigma_{i \\in node}Y_i (1 - T_i)}{\\Sigma_{i \\in node}(1 - T_i)}$$\n",
    "Тогда надо выбрать такое разбиение вершины, при котором максимизируется\n",
    "$$\\Delta = |\\tau_{left} - \\tau_{right}|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0988545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f576dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpliftTreeRegressor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth: int = 3, # максимальная глубина дерева.\n",
    "        min_samples_leaf: int = 1000, # минимальное необходимое число обучающих объектов в листе дерева.\n",
    "        min_samples_leaf_treated: int = 300, # минимальное необходимое число обучающих объектов с Т=1 в листе дерева.\n",
    "        min_samples_leaf_control: int = 300, # минимальное необходимое число обучающих объектов с Т=0 в листе дерева.\n",
    "    ):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_leaf_treated = min_samples_leaf_treated\n",
    "        self.min_samples_leaf_control = min_samples_leaf_control\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        X: np.ndarray,  # массив (n * k) с признаками.\n",
    "        treatment: np.ndarray,  # массив (n) с флагом воздействия.\n",
    "        y: np.ndarray  # массив (n) с целевой переменной.\n",
    "    ) -> None:\n",
    "        # fit the model\n",
    "        \n",
    "        def ate(idx: np.ndarray) -> float:\n",
    "            \"\"\"\n",
    "            Расчет ATE (Average Treatment Effect) = E[Y ∣T = 1] − E[Y ∣T = 0]\n",
    "            \"\"\"\n",
    "            y_ate = y[idx]\n",
    "            tr_ate = treatment[idx]\n",
    "            return (y_ate * tr_ate).sum() / tr_ate.sum() - (y_ate * (1 - tr_ate)).sum() / (1 - tr_ate).sum()\n",
    "        \n",
    "        def compute_delta_delta_p(idx1: np.ndarray, idx2: np.ndarray) -> float:\n",
    "            \"\"\"\n",
    "            Расчет критерия для разбиения элементов по листам\n",
    "            \"\"\"\n",
    "            tau_left = (y[idx1] * treatment[idx1]).sum() / treatment[idx1].sum() \\\n",
    "                        - (y[idx1] * (1 - treatment[idx1])).sum() / (1 - treatment[idx1]).sum()\n",
    "            tau_right = (y[idx2] * treatment[idx2]).sum() / treatment[idx2].sum() \\\n",
    "                        - (y[idx2] * (1 - treatment[idx2])).sum() / (1 - treatment[idx2]).sum()\n",
    "            return abs(tau_left - tau_right)\n",
    "        \n",
    "        \n",
    "        def build(idx: np.ndarray, parent: int, depth: int) -> None:\n",
    "            \"\"\"\n",
    "            Построение дерева и выделение 2 новых листов\n",
    "            :idx: np.ndarray - индексы элементов в текущем листе\n",
    "            \"\"\"\n",
    "            \n",
    "            # Построение текущего листа\n",
    "            leaf_id = len(self.tree)  # id текущего листа\n",
    "            leaf = {\n",
    "                'item_ids': idx,\n",
    "                'n_items': len(idx),\n",
    "                'ATE': ate(idx),\n",
    "                'split_feat': None,\n",
    "                'split_threshold': None,\n",
    "                'parent': parent,\n",
    "                'depth': depth,\n",
    "                'children': []\n",
    "            }\n",
    "            self.tree.append(leaf)\n",
    "            if parent >= 0:\n",
    "                self.tree[parent]['children'].append(leaf_id)\n",
    "            \n",
    "            if depth == self.max_depth:\n",
    "                return  # Достигли предельной глубины дерева\n",
    "            \n",
    "            items = X[idx]  # Все элементы в листе\n",
    "            ddps = {}  # словарь для значений критерия для всех возможных разбиений\n",
    "            # Перебираю все признаки\n",
    "            for i in range(X.shape[1]):\n",
    "                # Перебираю варианты порога\n",
    "                column_values = items[:, i]\n",
    "                unique_values = np.unique(column_values)\n",
    "                if len(unique_values) > 10:\n",
    "                    percentiles = np.percentile(column_values, [3, 5, 10, 20, 30, 50, 70, 80, 90, 95, 97])\n",
    "                else:\n",
    "                    percentiles = np.percentile(column_values, [10, 50, 90])\n",
    "                threshold_options = np.unique(percentiles)  # Значения порогов для перебора\n",
    "                for thr in threshold_options:\n",
    "                    # Разбиваю признак по порогу\n",
    "                    item_idx_left = idx[column_values <= thr]\n",
    "                    item_idx_right = idx[column_values > thr]\n",
    "                    if min(len(item_idx_left), len(item_idx_right)) < self.min_samples_leaf \\\n",
    "                            or treatment[item_idx_left].sum() < self.min_samples_leaf_treated \\\n",
    "                            or len(items) - treatment[item_idx_left].sum() < self.min_samples_leaf_control \\\n",
    "                            or treatment[item_idx_right].sum() < self.min_samples_leaf_treated \\\n",
    "                            or len(items) - treatment[item_idx_right].sum() < self.min_samples_leaf_control:\n",
    "                        continue  # Пропускаем порог, т.к. после разбиения не выполняются требования к новым листам\n",
    "                    # Считаю критерий delta_delta_p\n",
    "                    ddp = compute_delta_delta_p(item_idx_left, item_idx_right)\n",
    "                    ddps[(i, thr)] = ddp\n",
    "            \n",
    "            if not ddps:\n",
    "                return  # Ни один вариант разбиения не подошел\n",
    "            # Выбираем наилучшее по значению критерия разбиение.\n",
    "            factor, threshold = max(ddps, key=lambda x: ddps[x])\n",
    "            # Запоминаю условия разбиения (фактор и порог) в текущий лист\n",
    "            self.tree[leaf_id]['split_feat'] = f'feat{factor}'\n",
    "            self.tree[leaf_id]['split_threshold'] = threshold\n",
    "            # По лучшему разбиению создаем левую вершину и правую вершину.\n",
    "            column_values = items[:, factor]\n",
    "            item_idx_left = column_values <= threshold\n",
    "            item_idx_right = column_values > threshold\n",
    "            \n",
    "            build(idx[item_idx_left], parent=leaf_id, depth=depth+1)\n",
    "            build(idx[item_idx_right], parent=leaf_id, depth=depth+1)\n",
    "            # --- end build()---\n",
    "        \n",
    "        self.tree = []\n",
    "        # Запуск построения дерева\n",
    "        build(np.arange(len(X)), parent=-1, depth=0)\n",
    "        # В рамках этого задания первый узел считается нулевым (depth=0)\n",
    "        # Хотя в стандартных библиотеках он первый.\n",
    "    \n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> Iterable[float]:\n",
    "        # compute predictions\n",
    "        predictions = []\n",
    "        for item in X:\n",
    "            leaf_id = 0\n",
    "            # Пока есть дети\n",
    "            while self.tree[leaf_id]['children']:\n",
    "                factor = int(self.tree[leaf_id]['split_feat'][4:])\n",
    "                if item[factor] <= self.tree[leaf_id]['split_threshold']:\n",
    "                    leaf_id = self.tree[leaf_id]['children'][0]\n",
    "                else:\n",
    "                    leaf_id = self.tree[leaf_id]['children'][1]\n",
    "            pred = self.tree[leaf_id]['ATE']\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f364963",
   "metadata": {},
   "source": [
    "### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939df758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check(model_constructor, model_params: dict, X, treatment, y, X_test, pred_right) -> bool:\n",
    "    EPS = 1e-3\n",
    "    model = model_constructor(**model_params)\n",
    "    model.fit(X, treatment, y)\n",
    "    pred = np.array(model.predict(X_test)).reshape(len(X_test))\n",
    "    passed = (np.max(np.abs(pred - pred_right)) < EPS)\n",
    "    return passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6a890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'max_depth': 3,\n",
    "    'min_samples_leaf': 6000, # минимальное необходимое число обучающих объектов в листе дерева.\n",
    "    'min_samples_leaf_treated': 2500, # минимальное необходимое число обучающих объектов с Т=1 в листе дерева.\n",
    "    'min_samples_leaf_control': 2500, # минимальное необходимое число обучающих \n",
    "}\n",
    "# Проверочные данные\n",
    "example_X = np.load('data_homework/example_X.npy')\n",
    "example_treatment = np.load('data_homework/example_treatment.npy')\n",
    "example_y = np.load('data_homework/example_y.npy')\n",
    "# Ожидаемый результат\n",
    "example_preds = np.load('data_homework/example_preds.npy')  # Правильные прогнозы для Х"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1d36f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты проверки: True\n"
     ]
    }
   ],
   "source": [
    "res = _check(UpliftTreeRegressor, model_params, example_X, example_treatment, example_y, example_X, example_preds)\n",
    "print(f'Результаты проверки: {res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa8418",
   "metadata": {},
   "source": [
    "Проверка успешно пройдена!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9453e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
