{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12564e7",
   "metadata": {},
   "source": [
    "Урок 3.\n",
    "\n",
    "Тема: Коллаборативная фильтрация. Офлайн-метрики и валидация\n",
    "\n",
    "Видео лекции:\n",
    "https://www.youtube.com/watch?v=IXdV2r2bPF8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67984e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# расскоментируйте код ниже, чтобы установить все зависимости\n",
    "# !pip install -q \\\n",
    "#     pyarrow==12.0.1 \\\n",
    "#     polars==0.18.6 \\\n",
    "#     tqdm==4.65.0 \\\n",
    "#     scipy==1.10.1 \\\n",
    "#     scikit-learn==1.3.0 \\\n",
    "#     numpy==1.24.3 \\\n",
    "#     qdrant-client==1.3.1 \\\n",
    "#     faiss-cpu==1.7.4 \\\n",
    "#     redis==4.6.0 \\\n",
    "#     implicit==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17e95fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# раскоментируйте код ниже, чтобы скачать данные\n",
    "# !wget -q https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "# !unzip -q ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48c874e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucky/anaconda3/envs/main/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import redis\n",
    "import faiss\n",
    "import implicit\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from typing import List, Any\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PointStruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16160e2d",
   "metadata": {},
   "source": [
    "## MovieLens датасет\n",
    "\n",
    "В качестве данных будем использовать датасет с оценками к фильмам Movielens-100k. В нем есть поле ratings, в качестве позитивных событий мы будем считать то, что пользователь поставил оценку > 3 (такое правило принято в статьях, работающих с этим датасетом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b843a01b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (55_375, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>rating</th><th>timestamp</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>298</td><td>474</td><td>4</td><td>884182806</td></tr><tr><td>253</td><td>465</td><td>5</td><td>891628467</td></tr><tr><td>286</td><td>1014</td><td>5</td><td>879781125</td></tr><tr><td>200</td><td>222</td><td>5</td><td>876042340</td></tr><tr><td>122</td><td>387</td><td>5</td><td>879270459</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>421</td><td>498</td><td>4</td><td>892241344</td></tr><tr><td>495</td><td>1091</td><td>4</td><td>888637503</td></tr><tr><td>806</td><td>421</td><td>4</td><td>882388897</td></tr><tr><td>676</td><td>538</td><td>4</td><td>892685437</td></tr><tr><td>716</td><td>204</td><td>5</td><td>879795543</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (55_375, 4)\n",
       "┌─────────┬─────────┬────────┬───────────┐\n",
       "│ user_id ┆ item_id ┆ rating ┆ timestamp │\n",
       "│ ---     ┆ ---     ┆ ---    ┆ ---       │\n",
       "│ i64     ┆ i64     ┆ i64    ┆ i64       │\n",
       "╞═════════╪═════════╪════════╪═══════════╡\n",
       "│ 298     ┆ 474     ┆ 4      ┆ 884182806 │\n",
       "│ 253     ┆ 465     ┆ 5      ┆ 891628467 │\n",
       "│ 286     ┆ 1014    ┆ 5      ┆ 879781125 │\n",
       "│ 200     ┆ 222     ┆ 5      ┆ 876042340 │\n",
       "│ 122     ┆ 387     ┆ 5      ┆ 879270459 │\n",
       "│ …       ┆ …       ┆ …      ┆ …         │\n",
       "│ 421     ┆ 498     ┆ 4      ┆ 892241344 │\n",
       "│ 495     ┆ 1091    ┆ 4      ┆ 888637503 │\n",
       "│ 806     ┆ 421     ┆ 4      ┆ 882388897 │\n",
       "│ 676     ┆ 538     ┆ 4      ┆ 892685437 │\n",
       "│ 716     ┆ 204     ┆ 5      ┆ 879795543 │\n",
       "└─────────┴─────────┴────────┴───────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pl.read_csv(\n",
    "    'ml-100k/u.data',\n",
    "    separator='\\t',\n",
    "    has_header=False,\n",
    "    new_columns=['user_id', 'item_id', 'rating', 'timestamp']\n",
    ")\n",
    "# в качестве позитивной реакции возьмем оценки больше 3\n",
    "ratings = ratings.filter(pl.col('rating') > 3)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77812903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# возьмем последние 5% по времени в качестве отложенной выборки\n",
    "# все что до этого момента, будем использовать для обучения модели\n",
    "ts_threshold = ratings['timestamp'].quantile(0.95)\n",
    "holdout_set = ratings.filter(pl.col('timestamp') >= ts_threshold)\n",
    "ratings = ratings.filter(pl.col('timestamp') < ts_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92171b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TOP_K = 10\n",
    "\n",
    "\n",
    "def set_seed():\n",
    "    random.seed(RANDOM_STATE)\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "def fit_als(ratings: pl.DataFrame, als_params={\"factors\": 64}):\n",
    "    \"\"\"Метод обучает модель ALS и возвращает эмбеддинги пользователей и объектов\n",
    "    Про ALS мы поговорим в следующем уроке, а пока что воспользуемся реализацией из библиотеки implicit\n",
    "\n",
    "    :param ratings: датафрейм с рейтингами\n",
    "    :param als_params: параметры для обучения модели ALS\n",
    "    :return: (user_embeddings, item_embeddings)\n",
    "    \"\"\"\n",
    "    set_seed()\n",
    "\n",
    "    # соберем разреженную матрицу рейтингов\n",
    "    rows = ratings[\"user_id\"].to_numpy()\n",
    "    cols = ratings[\"item_id\"].to_numpy()\n",
    "    values = ratings[\"rating\"].to_numpy() if \"rating\" in ratings else np.ones_like(rows)\n",
    "    user_item_data = sp.csr_matrix((values, (rows, cols)))\n",
    "\n",
    "    # обучим модель ALS\n",
    "    als_params.setdefault(\"random_state\", RANDOM_STATE)\n",
    "    # если есть gpu, используем его для ускорения\n",
    "    als_params.setdefault(\"use_gpu\", implicit.gpu.HAS_CUDA)\n",
    "    \n",
    "    model = implicit.als.AlternatingLeastSquares(**als_params)\n",
    "    model.fit(user_item_data)\n",
    "\n",
    "    if als_params['use_gpu']:\n",
    "        return model.user_factors.to_numpy(), model.item_factors.to_numpy()\n",
    "\n",
    "    return model.user_factors, model.item_factors\n",
    "\n",
    "\n",
    "def get_recommendations(user_embs: np.array, item_embs: np.array, k: int = TOP_K):\n",
    "    # строим индекс объектов\n",
    "    index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "    index.add(item_embs)\n",
    "\n",
    "    # строим рекомендации с помощью dot-product расстояния\n",
    "    # с запасом, чтобы после фильтрации просмотренных осталось как минимум TOP_K\n",
    "    return index.search(user_embs, TOP_K * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554afec",
   "metadata": {},
   "source": [
    "## Метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f354b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_hitrate(y_rel: List[Any], y_rec: List[Any], k: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    :param y_rel: релевантные объекты\n",
    "    :param y_rec: рекомендованные объекты\n",
    "    :param k: число рекомендации для показа (top-K результаты)\n",
    "    :return: 1, если top-k рекомендации содержат как минимум один релевантный объект\n",
    "    \"\"\"\n",
    "    return int(len(set(y_rec[:k]).intersection(set(y_rel))) > 0)\n",
    "\n",
    "\n",
    "# метод для оценки качества на отложенной выборке\n",
    "# можно сначала посмотреть следующие ячейки, чтобы понять, что тут происходит\n",
    "def evaluate_holdout_set(\n",
    "    train_df: pl.DataFrame, user_embs: np.array, item_embs: np.array, k: int = TOP_K\n",
    "):\n",
    "    # строим индекс эмбеддингов объектов\n",
    "    index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "    index.add(item_embs)\n",
    "\n",
    "    hitrate_list = []\n",
    "    hitrate_list_by_type = {\"warm\": [], \"cold\": []}\n",
    "\n",
    "    # датафрейм с колонками user_id, train_item_ids, test_item_ids\n",
    "    # нам интересно провалидировать только по тем пользователям, которые есть в отложенной выборке\n",
    "    # поэтому train_item_ids может быть пустым\n",
    "    grouped_user_items = (\n",
    "        holdout_set.groupby(\"user_id\")\n",
    "        .agg(pl.col(\"item_id\").alias(\"test_item_ids\"))\n",
    "        .join(\n",
    "            train_df.groupby(\"user_id\").agg(pl.col(\"item_id\").alias(\"train_item_ids\")),\n",
    "            \"user_id\",\n",
    "            \"left\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # предподсчитаем рекомендации по эмбеддингам пользователей и объектов (только для warm пользователей)\n",
    "    _, recs = get_recommendations(user_embs, item_embs)\n",
    "\n",
    "    for user_id, test_ids, train_ids in grouped_user_items.rows():\n",
    "        if train_ids:\n",
    "            # если есть история для пользователя, то используем предподсчитанные рекомендации\n",
    "            user_history = train_ids\n",
    "\n",
    "            y_rel = test_ids\n",
    "            y_rec = [\n",
    "                item_id for item_id in recs[user_id] if item_id not in user_history\n",
    "            ]\n",
    "            hitrate_list_by_type[\"warm\"].append(user_hitrate(y_rel, y_rec, k))\n",
    "        else:\n",
    "            # если нет истории пользователя, то используем сумму эмбеддингов объектов\n",
    "            user_emb = np.zeros(item_embs.shape[1])\n",
    "            user_history = set()\n",
    "            \n",
    "            for i, item_ind in enumerate(test_ids[:-1]):\n",
    "                user_emb += item_embs[item_ind]\n",
    "                user_history.add(item_ind)\n",
    "                \n",
    "                # хотим порекомендовать следующий объект\n",
    "                y_rel = [test_ids[i + 1]]\n",
    "                y_rec = [\n",
    "                    item_id\n",
    "                    for item_id in index.search(user_emb[np.newaxis, :], k + 1)[1][0]\n",
    "                    if item_id not in user_history\n",
    "                ]\n",
    "\n",
    "                hitrate_list_by_type[\"cold\"].append(user_hitrate(y_rel, y_rec, k))\n",
    "            \n",
    "    all_users_hitrate = np.mean(hitrate_list_by_type[\"warm\"] + hitrate_list_by_type[\"cold\"])\n",
    "    warm_users_hitrate = np.mean(hitrate_list_by_type[\"warm\"]) if hitrate_list_by_type[\"warm\"] else 1.0\n",
    "    cold_users_hitrate = np.mean(hitrate_list_by_type[\"cold\"]) if hitrate_list_by_type[\"cold\"] else 1.0\n",
    "    return {\n",
    "        \"all\": all_users_hitrate,\n",
    "        \"warm\": warm_users_hitrate,\n",
    "        \"cold\": cold_users_hitrate,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098a163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert user_hitrate([1, 2, 3], [4, 5, 2], 3) == 1\n",
    "assert user_hitrate([1, 2, 3], [4, 5, 2], 2) == 0\n",
    "assert user_hitrate([1, 2, 3], [4, 5, 6], 10) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e3c7b",
   "metadata": {},
   "source": [
    "## Случайная вадидация\n",
    "\n",
    "Можно сказать, что в валидацию попадает какой-то процент взаимодействий, а в тренировочную выборку все остальное. С точки зрения реализации самый простой способ, однако совсем никак не контролирует дата-лики, когда информация из будущего оказывается в прошлом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1709332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    ratings,\n",
    "    # будем сэмплировать так, чтобы пользователи встречались с той же вероятностью\n",
    "    stratify=ratings['user_id'],\n",
    "    test_size=TEST_SIZE,\n",
    "    # зафиксируем генератор случайных чисел для воспроизводимости результатов\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b19ceacb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucky/anaconda3/envs/main/lib/python3.9/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "100%|███████████████████████████████████████████| 15/15 [00:00<00:00, 22.15it/s]\n"
     ]
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94a51848",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7862/312250852.py:2: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  train_user_items = train_df.groupby(\"user_id\").agg(\n",
      "/tmp/ipykernel_7862/312250852.py:5: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  test_user_items = test_df.groupby(\"user_id\").agg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (904, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>test_item_ids</th><th>train_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>6</td><td>[531, 274, … 534]</td><td>[64, 475, … 275]</td></tr><tr><td>271</td><td>[197, 697, … 69]</td><td>[605, 462, … 100]</td></tr><tr><td>920</td><td>[313]</td><td>[333, 340, … 310]</td></tr><tr><td>822</td><td>[189]</td><td>[408, 333, … 1110]</td></tr><tr><td>283</td><td>[175, 42, … 24]</td><td>[709, 211, … 627]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>893</td><td>[144, 118]</td><td>[471, 531, … 426]</td></tr><tr><td>253</td><td>[523, 294, … 510]</td><td>[300, 190, … 121]</td></tr><tr><td>95</td><td>[216, 178, … 523]</td><td>[399, 208, … 1221]</td></tr><tr><td>887</td><td>[926, 928, … 597]</td><td>[96, 755, … 385]</td></tr><tr><td>235</td><td>[1451, 83, … 179]</td><td>[193, 22, … 303]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (904, 3)\n",
       "┌─────────┬───────────────────┬────────────────────┐\n",
       "│ user_id ┆ test_item_ids     ┆ train_item_ids     │\n",
       "│ ---     ┆ ---               ┆ ---                │\n",
       "│ i64     ┆ list[i64]         ┆ list[i64]          │\n",
       "╞═════════╪═══════════════════╪════════════════════╡\n",
       "│ 6       ┆ [531, 274, … 534] ┆ [64, 475, … 275]   │\n",
       "│ 271     ┆ [197, 697, … 69]  ┆ [605, 462, … 100]  │\n",
       "│ 920     ┆ [313]             ┆ [333, 340, … 310]  │\n",
       "│ 822     ┆ [189]             ┆ [408, 333, … 1110] │\n",
       "│ 283     ┆ [175, 42, … 24]   ┆ [709, 211, … 627]  │\n",
       "│ …       ┆ …                 ┆ …                  │\n",
       "│ 893     ┆ [144, 118]        ┆ [471, 531, … 426]  │\n",
       "│ 253     ┆ [523, 294, … 510] ┆ [300, 190, … 121]  │\n",
       "│ 95      ┆ [216, 178, … 523] ┆ [399, 208, … 1221] │\n",
       "│ 887     ┆ [926, 928, … 597] ┆ [96, 755, … 385]   │\n",
       "│ 235     ┆ [1451, 83, … 179] ┆ [193, 22, … 303]   │\n",
       "└─────────┴───────────────────┴────────────────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сгруппируем в список индексов объекты из тренировочной выборки и валидационной\n",
    "train_user_items = train_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"train_item_ids\")\n",
    ")\n",
    "test_user_items = test_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"test_item_ids\")\n",
    ")\n",
    "# объединим все в одну табличку, при этом важно оставить всех тех\n",
    "# пользователей, которые есть в валидационной выборке\n",
    "grouped_user_items = test_user_items.join(train_user_items, \"user_id\", \"left\")\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "701c67d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 1.0\n"
     ]
    }
   ],
   "source": [
    "hitrate_list = []\n",
    "for user_id, user_history, y_rel in grouped_user_items.rows():\n",
    "    # строим рекомендации из тех объектов, которые уже не были в тренировочной выборке\n",
    "    y_rec = [item_id for item_id in recs[user_id] if item_id not in user_history]\n",
    "    hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5de03b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7862/2451764982.py:27: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  holdout_set.groupby(\"user_id\")\n",
      "/tmp/ipykernel_7862/2451764982.py:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  train_df.groupby(\"user_id\").agg(pl.col(\"item_id\").alias(\"train_item_ids\")),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'all': 0.058823529411764705,\n",
       " 'warm': 0.2028985507246377,\n",
       " 'cold': 0.052972336668628606}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca18a0d",
   "metadata": {},
   "source": [
    "На валидации получили идеальную метрику hitrate, однако на отложенной выборке самый худший результат по сравнению со следующими методами валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c0b1a",
   "metadata": {},
   "source": [
    "## Валидация по пользователям\n",
    "\n",
    "Здесь мы делаем разделение данных уже по полю user_id, то есть какие-то пользователи попадут только в тестовую выборку и с точки зрения алгоритма будут холодными (cold) пользователями\n",
    "\n",
    "Для того, чтобы построить рекомендации для таких пользователей, будем использовать эмбеддинги объектов в реальном времени. То есть если для валидации у нас есть список объектов [item_1, item_2, item_3, ...], то для первого объекта ничего не рекомендуем (или еще лучше рекомендовать популярные объекты). В момент рекомендации второго объекта у нас есть история для пользователя: [item_1], тогда эмбединг пользователя равен эмбеддингу item_1. Для следующего объекта эмбеддинг будет равен сумме эмбеддингов item_1 и item_2 и так далее.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87b1b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем генератор случайных чисел для воспроизводимости\n",
    "np.random.seed(RANDOM_STATE)  \n",
    "\n",
    "# выберем среди всех пользователей тех, кто будет в тренировочной выборке, а кто в тестовой\n",
    "unique_users = ratings[\"user_id\"].unique().to_list()\n",
    "test_users = set(\n",
    "    np.random.choice(unique_users, int(len(unique_users) * TEST_SIZE), replace=False)\n",
    ")\n",
    "train_users = set(unique_users).difference(test_users)\n",
    "\n",
    "train_df = ratings.filter(pl.col(\"user_id\").is_in(train_users))\n",
    "test_df = ratings.filter(pl.col(\"user_id\").is_in(test_users))\n",
    "\n",
    "# sanity check\n",
    "assert set(train_df[\"user_id\"].unique().to_list()) == train_users\n",
    "assert set(test_df[\"user_id\"].unique().to_list()) == test_users\n",
    "assert len(train_df) + len(test_df) == len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "076b344c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [00:00<00:00, 23.62it/s]\n"
     ]
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72030097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.06426440211154465\n"
     ]
    }
   ],
   "source": [
    "# строим индекс объектов\n",
    "index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "index.add(item_embs)\n",
    "    \n",
    "hitrate_list = []\n",
    "for _, user_session, _ in grouped_user_items.rows():\n",
    "    user_emb = np.zeros(item_embs.shape[1])\n",
    "    user_history = set()\n",
    "    # эмбеддинг пользователя - сумма эмбеддингов позитивных объектов\n",
    "    # пройдемся по каждому объекту и постараемся предсказать следующие в сессии\n",
    "    for i, item_ind in enumerate(user_session[:-1]):\n",
    "        user_emb += item_embs[item_ind]\n",
    "        user_history.add(item_ind)\n",
    "        \n",
    "        y_rel = [user_session[i + 1]]\n",
    "        y_rec = [\n",
    "            item_id \n",
    "            for item_id in index.search(user_emb[np.newaxis, :], TOP_K * 3)[1][0]\n",
    "            if item_id not in user_history\n",
    "        ]\n",
    "    \n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd292f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7862/2451764982.py:27: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  holdout_set.groupby(\"user_id\")\n",
      "/tmp/ipykernel_7862/2451764982.py:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  train_df.groupby(\"user_id\").agg(pl.col(\"item_id\").alias(\"train_item_ids\")),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'all': 0.05866228070175439,\n",
       " 'warm': 0.20967741935483872,\n",
       " 'cold': 0.053348467650397274}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a71c9",
   "metadata": {},
   "source": [
    "## Валидация по времени\n",
    "\n",
    "Такая валидация дублирует реально поведение системы, когда у нас есть данные только из прошлого и мы хотим порекомендовать для будущего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32c38de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_threshold = ratings['timestamp'].quantile(1 - TEST_SIZE)\n",
    "train_df = ratings.filter(pl.col('timestamp') < ts_threshold)\n",
    "test_df = ratings.filter(pl.col('timestamp') >= ts_threshold)\n",
    "\n",
    "assert len(train_df) + len(test_df) == len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37e7c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [00:00<00:00, 22.53it/s]\n"
     ]
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd3644c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7862/745071503.py:1: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  train_user_items = train_df.groupby('user_id').agg(\n",
      "/tmp/ipykernel_7862/745071503.py:4: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  test_user_items = test_df.groupby('user_id').agg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (126, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>test_item_ids</th><th>train_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>280</td><td>[631, 1, … 233]</td><td>null</td></tr><tr><td>420</td><td>[283, 302, … 547]</td><td>null</td></tr><tr><td>938</td><td>[864, 313, … 993]</td><td>null</td></tr><tr><td>39</td><td>[315, 352, … 319]</td><td>null</td></tr><tr><td>146</td><td>[1022, 262, … 311]</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>119</td><td>[451, 995]</td><td>[392, 1153, … 257]</td></tr><tr><td>393</td><td>[303, 302]</td><td>[1219, 471, … 613]</td></tr><tr><td>613</td><td>[258, 303, … 279]</td><td>null</td></tr><tr><td>488</td><td>[510, 748, … 705]</td><td>null</td></tr><tr><td>363</td><td>[405, 1495, … 181]</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (126, 3)\n",
       "┌─────────┬────────────────────┬────────────────────┐\n",
       "│ user_id ┆ test_item_ids      ┆ train_item_ids     │\n",
       "│ ---     ┆ ---                ┆ ---                │\n",
       "│ i64     ┆ list[i64]          ┆ list[i64]          │\n",
       "╞═════════╪════════════════════╪════════════════════╡\n",
       "│ 280     ┆ [631, 1, … 233]    ┆ null               │\n",
       "│ 420     ┆ [283, 302, … 547]  ┆ null               │\n",
       "│ 938     ┆ [864, 313, … 993]  ┆ null               │\n",
       "│ 39      ┆ [315, 352, … 319]  ┆ null               │\n",
       "│ 146     ┆ [1022, 262, … 311] ┆ null               │\n",
       "│ …       ┆ …                  ┆ …                  │\n",
       "│ 119     ┆ [451, 995]         ┆ [392, 1153, … 257] │\n",
       "│ 393     ┆ [303, 302]         ┆ [1219, 471, … 613] │\n",
       "│ 613     ┆ [258, 303, … 279]  ┆ null               │\n",
       "│ 488     ┆ [510, 748, … 705]  ┆ null               │\n",
       "│ 363     ┆ [405, 1495, … 181] ┆ null               │\n",
       "└─────────┴────────────────────┴────────────────────┘"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_items = train_df.groupby('user_id').agg(\n",
    "    pl.col('item_id').alias('train_item_ids')\n",
    ")\n",
    "test_user_items = test_df.groupby('user_id').agg(\n",
    "    pl.col('item_id').alias('test_item_ids')\n",
    ")\n",
    "grouped_user_items = test_user_items.join(train_user_items, 'user_id', 'left')\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffa80a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.0693731875975909\n"
     ]
    }
   ],
   "source": [
    "# строим индекс объектов\n",
    "index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "index.add(item_embs)\n",
    "    \n",
    "for user_id, test_ids, train_ids in grouped_user_items.rows():\n",
    "    if train_ids:\n",
    "        # используем инференс модели с помощью эмбеддинга пользователя\n",
    "        user_history = train_ids\n",
    "        \n",
    "        y_rel = test_ids\n",
    "        y_rec = [item_id for item_id in recs[user_id] if item_id not in user_history]\n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "    else:\n",
    "        # используем итеративный эмбеддинг по объектам\n",
    "        user_emb = np.zeros(item_embs.shape[1])\n",
    "        user_history = set()\n",
    "        for i, item_ind in enumerate(test_ids[:-1]):\n",
    "            if item_ind < len(item_embs):\n",
    "                user_emb += item_embs[item_ind]\n",
    "                \n",
    "            user_history.add(item_ind)    \n",
    "            y_rel = [test_ids[i + 1]]\n",
    "            y_rec = [\n",
    "                item_id \n",
    "                for item_id in index.search(user_emb[np.newaxis, :], TOP_K * 3)[1][0]\n",
    "                if item_id not in user_history\n",
    "            ]\n",
    "    \n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83a1a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7862/2451764982.py:27: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  holdout_set.groupby(\"user_id\")\n",
      "/tmp/ipykernel_7862/2451764982.py:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  train_df.groupby(\"user_id\").agg(pl.col(\"item_id\").alias(\"train_item_ids\")),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'all': 0.058151609553478714,\n",
       " 'warm': 0.22413793103448276,\n",
       " 'cold': 0.05299785867237687}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba7267",
   "metadata": {},
   "source": [
    "## Валидация по событиям\n",
    "\n",
    "В такой валидации мы рассматриваем для пользователя все взаимодействия, отсортированные по времени и оставляем последние N взаимодействия в качестве валидации, а все что раньше – для тренировки. У этого способа есть такая же проблема с тем, что при обучении могут сказываться дата-лики, однако в этом случае мы учитываем как холодных, так и теплых пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81b23fdd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7862/2082558794.py:2: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  ratings\n",
      "/tmp/ipykernel_7862/2082558794.py:6: DeprecationWarning: `apply` is deprecated. It has been renamed to `map_elements`.\n",
      "  pl.col('item_id').apply(lambda x: x[:-1]).alias('train_item_ids'),\n",
      "/tmp/ipykernel_7862/2082558794.py:7: DeprecationWarning: `apply` is deprecated. It has been renamed to `map_elements`.\n",
      "  pl.col('item_id').apply(lambda x: [x[-1]]).alias('test_item_ids')\n",
      "/tmp/ipykernel_7862/2082558794.py:14: DeprecationWarning: `apply` is deprecated. It has been renamed to `map_elements`.\n",
      "  .filter(pl.col('test_item_ids').apply(lambda x: len(x) == 0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (911, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>train_item_ids</th><th>test_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>548</td><td>[302, 750, … 460]</td><td>[1278]</td></tr><tr><td>569</td><td>[302, 286, … 274]</td><td>[287]</td></tr><tr><td>542</td><td>[315, 509, … 230]</td><td>[12]</td></tr><tr><td>929</td><td>[515, 100, … 419]</td><td>[56]</td></tr><tr><td>399</td><td>[302, 301, … 779]</td><td>[817]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>363</td><td>[302, 313, … 444]</td><td>[859]</td></tr><tr><td>774</td><td>[238, 202, … 98]</td><td>[219]</td></tr><tr><td>95</td><td>[151, 683, … 1116]</td><td>[445]</td></tr><tr><td>125</td><td>[173, 434, … 209]</td><td>[270]</td></tr><tr><td>241</td><td>[286, 750, … 880]</td><td>[292]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (911, 3)\n",
       "┌─────────┬────────────────────┬───────────────┐\n",
       "│ user_id ┆ train_item_ids     ┆ test_item_ids │\n",
       "│ ---     ┆ ---                ┆ ---           │\n",
       "│ i64     ┆ list[i64]          ┆ list[i64]     │\n",
       "╞═════════╪════════════════════╪═══════════════╡\n",
       "│ 548     ┆ [302, 750, … 460]  ┆ [1278]        │\n",
       "│ 569     ┆ [302, 286, … 274]  ┆ [287]         │\n",
       "│ 542     ┆ [315, 509, … 230]  ┆ [12]          │\n",
       "│ 929     ┆ [515, 100, … 419]  ┆ [56]          │\n",
       "│ 399     ┆ [302, 301, … 779]  ┆ [817]         │\n",
       "│ …       ┆ …                  ┆ …             │\n",
       "│ 363     ┆ [302, 313, … 444]  ┆ [859]         │\n",
       "│ 774     ┆ [238, 202, … 98]   ┆ [219]         │\n",
       "│ 95      ┆ [151, 683, … 1116] ┆ [445]         │\n",
       "│ 125     ┆ [173, 434, … 209]  ┆ [270]         │\n",
       "│ 241     ┆ [286, 750, … 880]  ┆ [292]         │\n",
       "└─────────┴────────────────────┴───────────────┘"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_user_items = (\n",
    "    ratings\n",
    "    .sort('timestamp')\n",
    "    .groupby('user_id')\n",
    "    .agg([\n",
    "        pl.col('item_id').apply(lambda x: x[:-1]).alias('train_item_ids'),\n",
    "        pl.col('item_id').apply(lambda x: [x[-1]]).alias('test_item_ids')\n",
    "    ])\n",
    ")\n",
    "\n",
    "# sanity check\n",
    "assert len(\n",
    "    grouped_user_items\n",
    "    .filter(pl.col('test_item_ids').apply(lambda x: len(x) == 0))\n",
    ") == 0\n",
    "\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfa4b783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [00:00<00:00, 26.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = (\n",
    "    grouped_user_items\n",
    "    .select('user_id', 'train_item_ids')\n",
    "    .explode('train_item_ids')\n",
    "    .rename({'train_item_ids': 'item_id'})\n",
    ")\n",
    "\n",
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86e96425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.09659714599341383\n"
     ]
    }
   ],
   "source": [
    "hitrate_list = []\n",
    "for user_id, user_history, y_rel in grouped_user_items.rows():\n",
    "    y_rec = [\n",
    "        item_id\n",
    "        for item_id in recs[user_id]\n",
    "        if item_id not in user_history\n",
    "    ]\n",
    "    hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2794ee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7862/2451764982.py:27: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  holdout_set.groupby(\"user_id\")\n",
      "/tmp/ipykernel_7862/2451764982.py:30: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  train_df.groupby(\"user_id\").agg(pl.col(\"item_id\").alias(\"train_item_ids\")),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'all': 0.07409502262443439,\n",
       " 'warm': 0.21739130434782608,\n",
       " 'cold': 0.06827545615067687}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fcf2e9",
   "metadata": {},
   "source": [
    "## Approximate KNN с помощью Qdrant\n",
    "\n",
    "В отдельном процессе нужно запустить серверную часть [qdrant](https://qdrant.tech/) следующей командой:\n",
    "\n",
    "`docker run -p 6333:6333 qdrant/qdrant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a6394cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "client.recreate_collection(\n",
    "    collection_name=\"item_embs\",\n",
    "    # задаем размерность векторов и метрику дистанции\n",
    "    vectors_config=VectorParams(size=item_embs.shape[1], distance=Distance.DOT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84ae462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operation_info = client.upsert(\n",
    "    collection_name=\"item_embs\",\n",
    "    wait=True,\n",
    "    points=[\n",
    "        PointStruct(id=(item_id + 1), vector=item_emb.tolist())\n",
    "        for item_id, item_emb in enumerate(item_embs[1:])\n",
    "    ]\n",
    ")\n",
    "operation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d4c9326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=228, version=0, score=0.341433, payload={}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=202, version=0, score=0.30895153, payload={}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=222, version=0, score=0.29705077, payload={}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=405, version=0, score=0.2686637, payload={}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=227, version=0, score=0.25709012, payload={}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=230, version=0, score=0.24627134, payload={}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=229, version=0, score=0.18338814, payload={}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=380, version=0, score=0.17153707, payload={}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=151, version=0, score=0.17020312, payload={}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=271, version=0, score=0.13478002, payload={}, vector=None, shard_key=None)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 183\n",
    "search_result = client.search(\n",
    "    collection_name=\"item_embs\",\n",
    "    query_vector=user_embs[user_id].tolist(),\n",
    "    limit=TOP_K\n",
    ")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5af269c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rel = holdout_set.filter(pl.col('user_id') == user_id)['item_id'].to_list()\n",
    "y_rec = [s.id for s in search_result]\n",
    "user_hitrate(y_rel, y_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9cc743",
   "metadata": {},
   "source": [
    "## watched filter с разреженной матрицей\n",
    "\n",
    "Для работы с redis нужно запустить docker контейнер следующей командой:\n",
    "\n",
    "`docker run --rm -p 6379:6379 redis/redis-stack-server:latest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7887ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "n_interactions = 10_000\n",
    "n_users = 10_000\n",
    "n_items = 1_000_000\n",
    "\n",
    "# wanna generate sparse matrix\n",
    "assert n_interactions <= n_users * n_items / 100\n",
    "\n",
    "interactions = set()\n",
    "\n",
    "for _ in range(n_interactions):\n",
    "    while True:\n",
    "        user = np.random.choice(n_users)\n",
    "        item = np.random.choice(n_items)\n",
    "\n",
    "        if (item, user) not in interactions:\n",
    "            interactions.add((item, user))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03b2ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(host='localhost', db=0)\n",
    "used_memory_before = r.info('memory')['used_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22d321b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, user in interactions:\n",
    "    r.set(f'{item}-{user}', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7253ab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "611064"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.info('memory')['used_memory'] - used_memory_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffdd76a",
   "metadata": {},
   "source": [
    "Использовали ~500Кб памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e39a79cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0715 ± 0.0205 ms\n"
     ]
    }
   ],
   "source": [
    "for item, user in interactions:\n",
    "    assert r.get(f'{item}-{user}') is not None\n",
    "    \n",
    "get_time_elapsed = []\n",
    "for _ in range(n_interactions):\n",
    "    user = np.random.choice(n_users)\n",
    "    item = np.random.choice(n_items)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    get_result = r.get(f'{item}-{user}')\n",
    "    get_time_elapsed.append((time.time() - t_start) * 1_000)\n",
    "    \n",
    "    if (item, user) in interactions:\n",
    "        assert get_result is not None\n",
    "        \n",
    "print(f'{np.mean(get_time_elapsed):.4f} ± {np.std(get_time_elapsed):.4f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed360e2",
   "metadata": {},
   "source": [
    "## Watched filter с помощью redis\n",
    "\n",
    "https://redis-py.readthedocs.io/en/stable/redismodules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca07f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(db=1)\n",
    "used_memory_before = r.info('memory')['used_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fc9c8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "r = redis.Redis()\n",
    "r.bf().create(\"bloom\", 0.01, 1000)\n",
    "r.bf().add(\"bloom\", \"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ddb495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# создадим БД watched_filter, которая будет расчитана на предопределенное число интеракций\n",
    "# и делать в среднем 0.1% (вероятность делится на 100) ложноположительных срабатываний\n",
    "# r.bf().reserve('watched_filter', 0.001, n_interactions)\n",
    "r.bf().create('bloom', 0.001, n_interactions)\n",
    "\n",
    "# for item, user in interactions:\n",
    "#     r.bf().add('watched_filter', f'{item}-{user}')\n",
    "    \n",
    "# for item, user in interactions:\n",
    "#     assert r.bf().exists('watched_filter', f'{item}-{user}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f360deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20944"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.info('memory')['used_memory'] - used_memory_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24beb5b",
   "metadata": {},
   "source": [
    "Для хранения используем в ~ 30 раз меньше памяти\n",
    "\n",
    "Теперь проверим, изменилось ли время работы и сколько ложноположительных срабатываний произошло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_errors = 0\n",
    "get_time_elapsed = []\n",
    "\n",
    "for _ in range(n_interactions):\n",
    "    user = np.random.choice(n_users)\n",
    "    item = np.random.choice(n_items)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    get_result = r.bf().exists('watched_filter', f'{item}-{user}')\n",
    "    get_time_elapsed.append((time.time() - t_start) * 1_000)\n",
    "    \n",
    "    if (item, user) in interactions and get_result == 0:\n",
    "        raise Exception('У bloom filter не бывает ложноотрицательных срабатываний')\n",
    "    if (item, user) not in interactions and get_result == 1:\n",
    "        num_errors += 1\n",
    "        \n",
    "print(f'Количество ложноположительных ошибок: {num_errors}')\n",
    "print(f'{np.mean(get_time_elapsed):.4f} ± {np.std(get_time_elapsed):.4f} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a57c32a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
