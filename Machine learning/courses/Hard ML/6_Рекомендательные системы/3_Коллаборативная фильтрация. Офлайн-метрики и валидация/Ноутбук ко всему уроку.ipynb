{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87412ea2",
   "metadata": {},
   "source": [
    "Урок 3.\n",
    "\n",
    "Тема: Коллаборативная фильтрация. Офлайн-метрики и валидация\n",
    "\n",
    "Видео лекции:\n",
    "https://www.youtube.com/watch?v=IXdV2r2bPF8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67984e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# расскоментируйте код ниже, чтобы установить все зависимости\n",
    "# !pip install -q \\\n",
    "#     pyarrow==12.0.1 \\\n",
    "#     polars==0.18.6 \\\n",
    "#     tqdm==4.65.0 \\\n",
    "#     scipy==1.10.1 \\\n",
    "#     scikit-learn==1.3.0 \\\n",
    "#     numpy==1.24.3 \\\n",
    "#     qdrant-client==1.3.1 \\\n",
    "#     faiss-cpu==1.7.4 \\\n",
    "#     redis==4.6.0 \\\n",
    "#     implicit==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e95fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# раскоментируйте код ниже, чтобы скачать данные\n",
    "# !wget -q https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "# !unzip -q ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48c874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import redis\n",
    "import faiss\n",
    "import implicit\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from typing import List, Any\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PointStruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16160e2d",
   "metadata": {},
   "source": [
    "## MovieLens датасет\n",
    "\n",
    "В качестве данных будем использовать датасет с оценками к фильмам Movielens-100k. В нем есть поле ratings, в качестве позитивных событий мы будем считать то, что пользователь поставил оценку > 3 (такое правило принято в статьях, работающих с этим датасетом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b843a01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (55_375, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>rating</th><th>timestamp</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>298</td><td>474</td><td>4</td><td>884182806</td></tr><tr><td>253</td><td>465</td><td>5</td><td>891628467</td></tr><tr><td>286</td><td>1014</td><td>5</td><td>879781125</td></tr><tr><td>200</td><td>222</td><td>5</td><td>876042340</td></tr><tr><td>122</td><td>387</td><td>5</td><td>879270459</td></tr><tr><td>291</td><td>1042</td><td>4</td><td>874834944</td></tr><tr><td>119</td><td>392</td><td>4</td><td>886176814</td></tr><tr><td>167</td><td>486</td><td>4</td><td>892738452</td></tr><tr><td>299</td><td>144</td><td>4</td><td>877881320</td></tr><tr><td>308</td><td>1</td><td>4</td><td>887736532</td></tr><tr><td>38</td><td>95</td><td>5</td><td>892430094</td></tr><tr><td>63</td><td>277</td><td>4</td><td>875747401</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>429</td><td>199</td><td>5</td><td>882386006</td></tr><tr><td>897</td><td>369</td><td>4</td><td>879993713</td></tr><tr><td>936</td><td>287</td><td>4</td><td>886832419</td></tr><tr><td>821</td><td>151</td><td>4</td><td>874792889</td></tr><tr><td>113</td><td>975</td><td>5</td><td>875936424</td></tr><tr><td>864</td><td>685</td><td>4</td><td>888891900</td></tr><tr><td>617</td><td>582</td><td>4</td><td>883789294</td></tr><tr><td>421</td><td>498</td><td>4</td><td>892241344</td></tr><tr><td>495</td><td>1091</td><td>4</td><td>888637503</td></tr><tr><td>806</td><td>421</td><td>4</td><td>882388897</td></tr><tr><td>676</td><td>538</td><td>4</td><td>892685437</td></tr><tr><td>716</td><td>204</td><td>5</td><td>879795543</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (55_375, 4)\n",
       "┌─────────┬─────────┬────────┬───────────┐\n",
       "│ user_id ┆ item_id ┆ rating ┆ timestamp │\n",
       "│ ---     ┆ ---     ┆ ---    ┆ ---       │\n",
       "│ i64     ┆ i64     ┆ i64    ┆ i64       │\n",
       "╞═════════╪═════════╪════════╪═══════════╡\n",
       "│ 298     ┆ 474     ┆ 4      ┆ 884182806 │\n",
       "│ 253     ┆ 465     ┆ 5      ┆ 891628467 │\n",
       "│ 286     ┆ 1014    ┆ 5      ┆ 879781125 │\n",
       "│ 200     ┆ 222     ┆ 5      ┆ 876042340 │\n",
       "│ …       ┆ …       ┆ …      ┆ …         │\n",
       "│ 495     ┆ 1091    ┆ 4      ┆ 888637503 │\n",
       "│ 806     ┆ 421     ┆ 4      ┆ 882388897 │\n",
       "│ 676     ┆ 538     ┆ 4      ┆ 892685437 │\n",
       "│ 716     ┆ 204     ┆ 5      ┆ 879795543 │\n",
       "└─────────┴─────────┴────────┴───────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pl.read_csv(\n",
    "    'ml-100k/u.data',\n",
    "    separator='\\t',\n",
    "    has_header=False,\n",
    "    new_columns=['user_id', 'item_id', 'rating', 'timestamp']\n",
    ")\n",
    "# в качестве позитивной реакции возьмем оценки больше 3\n",
    "ratings = ratings.filter(pl.col('rating') > 3)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77812903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# возьмем последние 5% по времени в качестве отложенной выборки\n",
    "# все что до этого момента, будем использовать для обучения модели\n",
    "ts_threshold = ratings['timestamp'].quantile(0.95)\n",
    "holdout_set = ratings.filter(pl.col('timestamp') >= ts_threshold)\n",
    "ratings = ratings.filter(pl.col('timestamp') < ts_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92171b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TOP_K = 10\n",
    "\n",
    "\n",
    "def set_seed():\n",
    "    random.seed(RANDOM_STATE)\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "def fit_als(ratings: pl.DataFrame, als_params={\"factors\": 64}):\n",
    "    \"\"\"Метод обучает модель ALS и возвращает эмбеддинги пользователей и объектов\n",
    "    Про ALS мы поговорим в следующем уроке, а пока что воспользуемся реализацией из библиотеки implicit\n",
    "\n",
    "    :param ratings: датафрейм с рейтингами\n",
    "    :param als_params: параметры для обучения модели ALS\n",
    "    :return: (user_embeddings, item_embeddings)\n",
    "    \"\"\"\n",
    "    set_seed()\n",
    "\n",
    "    # соберем разреженную матрицу рейтингов\n",
    "    rows = ratings[\"user_id\"].to_numpy()\n",
    "    cols = ratings[\"item_id\"].to_numpy()\n",
    "    values = ratings[\"rating\"].to_numpy() if \"rating\" in ratings else np.ones_like(rows)\n",
    "    user_item_data = sp.csr_matrix((values, (rows, cols)))\n",
    "\n",
    "    # обучим модель ALS\n",
    "    als_params.setdefault(\"random_state\", RANDOM_STATE)\n",
    "    # если есть gpu, используем его для ускорения\n",
    "    als_params.setdefault(\"use_gpu\", implicit.gpu.HAS_CUDA)\n",
    "    \n",
    "    model = implicit.als.AlternatingLeastSquares(**als_params)\n",
    "    model.fit(user_item_data)\n",
    "\n",
    "    if als_params['use_gpu']:\n",
    "        return model.user_factors.to_numpy(), model.item_factors.to_numpy()\n",
    "\n",
    "    return model.user_factors, model.item_factors\n",
    "\n",
    "\n",
    "def get_recommendations(user_embs: np.array, item_embs: np.array, k: int = TOP_K):\n",
    "    # строим индекс объектов\n",
    "    index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "    index.add(item_embs)\n",
    "\n",
    "    # строим рекомендации с помощью dot-product расстояния\n",
    "    # с запасом, чтобы после фильтрации просмотренных осталось как минимум TOP_K\n",
    "    return index.search(user_embs, TOP_K * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554afec",
   "metadata": {},
   "source": [
    "## Метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f354b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_hitrate(y_rel: List[Any], y_rec: List[Any], k: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    :param y_rel: релевантные объекты\n",
    "    :param y_rec: рекомендованные объекты\n",
    "    :param k: число рекомендации для показа (top-K результаты)\n",
    "    :return: 1, если top-k рекомендации содержат как минимум один релевантный объект\n",
    "    \"\"\"\n",
    "    return int(len(set(y_rec[:k]).intersection(set(y_rel))) > 0)\n",
    "\n",
    "\n",
    "# метод для оценки качества на отложенной выборке\n",
    "# можно сначала посмотреть следующие ячейки, чтобы понять, что тут происходит\n",
    "def evaluate_holdout_set(\n",
    "    train_df: pl.DataFrame, user_embs: np.array, item_embs: np.array, k: int = TOP_K\n",
    "):\n",
    "    # строим индекс эмбеддингов объектов\n",
    "    index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "    index.add(item_embs)\n",
    "\n",
    "    hitrate_list = []\n",
    "    hitrate_list_by_type = {\"warm\": [], \"cold\": []}\n",
    "\n",
    "    # датафрейм с колонками user_id, train_item_ids, test_item_ids\n",
    "    # нам интересно провалидировать только по тем пользователям, которые есть в отложенной выборке\n",
    "    # поэтому train_item_ids может быть пустым\n",
    "    grouped_user_items = (\n",
    "        holdout_set.groupby(\"user_id\")\n",
    "        .agg(pl.col(\"item_id\").alias(\"test_item_ids\"))\n",
    "        .join(\n",
    "            train_df.groupby(\"user_id\").agg(pl.col(\"item_id\").alias(\"train_item_ids\")),\n",
    "            \"user_id\",\n",
    "            \"left\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # предподсчитаем рекомендации по эмбеддингам пользователей и объектов (только для warm пользователей)\n",
    "    _, recs = get_recommendations(user_embs, item_embs)\n",
    "\n",
    "    for user_id, test_ids, train_ids in grouped_user_items.rows():\n",
    "        if train_ids:\n",
    "            # если есть история для пользователя, то используем предподсчитанные рекомендации\n",
    "            user_history = train_ids\n",
    "\n",
    "            y_rel = test_ids\n",
    "            y_rec = [\n",
    "                item_id for item_id in recs[user_id] if item_id not in user_history\n",
    "            ]\n",
    "            hitrate_list_by_type[\"warm\"].append(user_hitrate(y_rel, y_rec, k))\n",
    "        else:\n",
    "            # если нет истории пользователя, то используем сумму эмбеддингов объектов\n",
    "            user_emb = np.zeros(item_embs.shape[1])\n",
    "            user_history = set()\n",
    "            \n",
    "            for i, item_ind in enumerate(test_ids[:-1]):\n",
    "                user_emb += item_embs[item_ind]\n",
    "                user_history.add(item_ind)\n",
    "                \n",
    "                # хотим порекомендовать следующий объект\n",
    "                y_rel = [test_ids[i + 1]]\n",
    "                y_rec = [\n",
    "                    item_id\n",
    "                    for item_id in index.search(user_emb[np.newaxis, :], k + 1)[1][0]\n",
    "                    if item_id not in user_history\n",
    "                ]\n",
    "\n",
    "                hitrate_list_by_type[\"cold\"].append(user_hitrate(y_rel, y_rec, k))\n",
    "            \n",
    "    all_users_hitrate = np.mean(hitrate_list_by_type[\"warm\"] + hitrate_list_by_type[\"cold\"])\n",
    "    warm_users_hitrate = np.mean(hitrate_list_by_type[\"warm\"]) if hitrate_list_by_type[\"warm\"] else 1.0\n",
    "    cold_users_hitrate = np.mean(hitrate_list_by_type[\"cold\"]) if hitrate_list_by_type[\"cold\"] else 1.0\n",
    "    return {\n",
    "        \"all\": all_users_hitrate,\n",
    "        \"warm\": warm_users_hitrate,\n",
    "        \"cold\": cold_users_hitrate,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098a163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert user_hitrate([1, 2, 3], [4, 5, 2], 3) == 1\n",
    "assert user_hitrate([1, 2, 3], [4, 5, 2], 2) == 0\n",
    "assert user_hitrate([1, 2, 3], [4, 5, 6], 10) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e3c7b",
   "metadata": {},
   "source": [
    "## Случайная вадидация\n",
    "\n",
    "Можно сказать, что в валидацию попадает какой-то процент взаимодействий, а в тренировочную выборку все остальное. С точки зрения реализации самый простой способ, однако совсем никак не контролирует дата-лики, когда информация из будущего оказывается в прошлом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1709332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    ratings,\n",
    "    # будем сэмплировать так, чтобы пользователи встречались с той же вероятностью\n",
    "    stratify=ratings['user_id'],\n",
    "    test_size=TEST_SIZE,\n",
    "    # зафиксируем генератор случайных чисел для воспроизводимости результатов\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b19ceacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f184dab5f64823b588ac8c4a41cdaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a51848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (904, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>test_item_ids</th><th>train_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>816</td><td>[294, 349]</td><td>[678, 328, … 326]</td></tr><tr><td>496</td><td>[774, 68, … 268]</td><td>[89, 133, … 42]</td></tr><tr><td>352</td><td>[234, 385, 96]</td><td>[181, 39, … 657]</td></tr><tr><td>720</td><td>[268, 898]</td><td>[286, 258, … 262]</td></tr><tr><td>648</td><td>[109, 323, … 208]</td><td>[1003, 177, … 184]</td></tr><tr><td>784</td><td>[303, 302, 304]</td><td>[346, 344, … 690]</td></tr><tr><td>584</td><td>[109]</td><td>[114, 161, … 228]</td></tr><tr><td>368</td><td>[183, 774]</td><td>[551, 313, … 11]</td></tr><tr><td>360</td><td>[423, 735, … 515]</td><td>[223, 100, … 28]</td></tr><tr><td>472</td><td>[27, 373, … 1248]</td><td>[780, 1139, … 1058]</td></tr><tr><td>624</td><td>[7, 250, … 282]</td><td>[1048, 1012, … 690]</td></tr><tr><td>728</td><td>[322, 282]</td><td>[287, 471, … 100]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>791</td><td>[327, 322]</td><td>[289, 300, … 304]</td></tr><tr><td>255</td><td>[98, 559]</td><td>[834, 219, … 288]</td></tr><tr><td>351</td><td>[1316, 990, 359]</td><td>[750, 332, … 879]</td></tr><tr><td>511</td><td>[346, 260]</td><td>[288, 1527, … 887]</td></tr><tr><td>527</td><td>[513, 182, … 185]</td><td>[1149, 631, … 174]</td></tr><tr><td>495</td><td>[227, 79, … 282]</td><td>[404, 230, … 185]</td></tr><tr><td>215</td><td>[222, 357, … 434]</td><td>[483, 54, … 168]</td></tr><tr><td>447</td><td>[181, 1142, … 22]</td><td>[591, 1326, … 234]</td></tr><tr><td>727</td><td>[259, 491, … 511]</td><td>[173, 576, … 96]</td></tr><tr><td>47</td><td>[268]</td><td>[303, 258, … 289]</td></tr><tr><td>7</td><td>[550, 596, … 527]</td><td>[237, 648, … 660]</td></tr><tr><td>927</td><td>[29, 1089, … 328]</td><td>[138, 111, … 63]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (904, 3)\n",
       "┌─────────┬───────────────────┬───────────────────┐\n",
       "│ user_id ┆ test_item_ids     ┆ train_item_ids    │\n",
       "│ ---     ┆ ---               ┆ ---               │\n",
       "│ i64     ┆ list[i64]         ┆ list[i64]         │\n",
       "╞═════════╪═══════════════════╪═══════════════════╡\n",
       "│ 816     ┆ [294, 349]        ┆ [678, 328, … 326] │\n",
       "│ 496     ┆ [774, 68, … 268]  ┆ [89, 133, … 42]   │\n",
       "│ 352     ┆ [234, 385, 96]    ┆ [181, 39, … 657]  │\n",
       "│ 720     ┆ [268, 898]        ┆ [286, 258, … 262] │\n",
       "│ …       ┆ …                 ┆ …                 │\n",
       "│ 727     ┆ [259, 491, … 511] ┆ [173, 576, … 96]  │\n",
       "│ 47      ┆ [268]             ┆ [303, 258, … 289] │\n",
       "│ 7       ┆ [550, 596, … 527] ┆ [237, 648, … 660] │\n",
       "│ 927     ┆ [29, 1089, … 328] ┆ [138, 111, … 63]  │\n",
       "└─────────┴───────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сгруппируем в список индексов объекты из тренировочной выборки и валидационной\n",
    "train_user_items = train_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"train_item_ids\")\n",
    ")\n",
    "test_user_items = test_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"test_item_ids\")\n",
    ")\n",
    "# объединим все в одну табличку, при этом важно оставить всех тех\n",
    "# пользователей, которые есть в валидационной выборке\n",
    "grouped_user_items = test_user_items.join(train_user_items, \"user_id\", \"left\")\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "701c67d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 1.0\n"
     ]
    }
   ],
   "source": [
    "hitrate_list = []\n",
    "for user_id, user_history, y_rel in grouped_user_items.rows():\n",
    "    # строим рекомендации из тех объектов, которые уже не были в тренировочной выборке\n",
    "    y_rec = [item_id for item_id in recs[user_id] if item_id not in user_history]\n",
    "    hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de03b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.060520361990950226,\n",
       " 'warm': 0.21739130434782608,\n",
       " 'cold': 0.05414949970570924}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca18a0d",
   "metadata": {},
   "source": [
    "На валидации получили идеальную метрику hitrate, однако на отложенной выборке самый худший результат по сравнению со следующими методами валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c0b1a",
   "metadata": {},
   "source": [
    "## Валидация по пользователям\n",
    "\n",
    "Здесь мы делаем разделение данных уже по полю user_id, то есть какие-то пользователи попадут только в тестовую выборку и с точки зрения алгоритма будут холодными (cold) пользователями\n",
    "\n",
    "Для того, чтобы построить рекомендации для таких пользователей, будем использовать эмбеддинги объектов в реальном времени. То есть если для валидации у нас есть список объектов [item_1, item_2, item_3, ...], то для первого объекта ничего не рекомендуем (или еще лучше рекомендовать популярные объекты). В момент рекомендации второго объекта у нас есть история для пользователя: [item_1], тогда эмбединг пользователя равен эмбеддингу item_1. Для следующего объекта эмбеддинг будет равен сумме эмбеддингов item_1 и item_2 и так далее.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87b1b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем генератор случайных чисел для воспроизводимости\n",
    "np.random.seed(RANDOM_STATE)  \n",
    "\n",
    "# выберем среди всех пользователей тех, кто будет в тренировочной выборке, а кто в тестовой\n",
    "unique_users = ratings[\"user_id\"].unique().to_list()\n",
    "test_users = set(\n",
    "    np.random.choice(unique_users, int(len(unique_users) * TEST_SIZE), replace=False)\n",
    ")\n",
    "train_users = set(unique_users).difference(test_users)\n",
    "\n",
    "train_df = ratings.filter(pl.col(\"user_id\").is_in(train_users))\n",
    "test_df = ratings.filter(pl.col(\"user_id\").is_in(test_users))\n",
    "\n",
    "# sanity check\n",
    "assert set(train_df[\"user_id\"].unique().to_list()) == train_users\n",
    "assert set(test_df[\"user_id\"].unique().to_list()) == test_users\n",
    "assert len(train_df) + len(test_df) == len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "076b344c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddf488bff4845cfab7d21aca9cd5764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72030097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.1615863264020164\n"
     ]
    }
   ],
   "source": [
    "# строим индекс объектов\n",
    "index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "index.add(item_embs)\n",
    "    \n",
    "hitrate_list = []\n",
    "for _, user_session, _ in grouped_user_items.rows():\n",
    "    user_emb = np.zeros(item_embs.shape[1])\n",
    "    user_history = set()\n",
    "    # эмбеддинг пользователя - сумма эмбеддингов позитивных объектов\n",
    "    # пройдемся по каждому объекту и постараемся предсказать следующие в сессии\n",
    "    for i, item_ind in enumerate(user_session[:-1]):\n",
    "        user_emb += item_embs[item_ind]\n",
    "        user_history.add(item_ind)\n",
    "        \n",
    "        y_rel = [user_session[i + 1]]\n",
    "        y_rec = [\n",
    "            item_id \n",
    "            for item_id in index.search(user_emb[np.newaxis, :], TOP_K * 3)[1][0]\n",
    "            if item_id not in user_history\n",
    "        ]\n",
    "    \n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd292f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.06085526315789474,\n",
       " 'warm': 0.27419354838709675,\n",
       " 'cold': 0.053348467650397274}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a71c9",
   "metadata": {},
   "source": [
    "## Валидация по времени\n",
    "\n",
    "Такая валидация дублирует реально поведение системы, когда у нас есть данные только из прошлого и мы хотим порекомендовать для будущего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32c38de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_threshold = ratings['timestamp'].quantile(1 - TEST_SIZE)\n",
    "train_df = ratings.filter(pl.col('timestamp') < ts_threshold)\n",
    "test_df = ratings.filter(pl.col('timestamp') >= ts_threshold)\n",
    "\n",
    "assert len(train_df) + len(test_df) == len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "37e7c9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39aae2fe2037466a87c3273956a5cc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd3644c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (126, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>test_item_ids</th><th>train_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>488</td><td>[510, 748, … 705]</td><td>null</td></tr><tr><td>704</td><td>[205, 354, … 134]</td><td>null</td></tr><tr><td>776</td><td>[168, 127, … 523]</td><td>null</td></tr><tr><td>720</td><td>[258, 304, … 242]</td><td>null</td></tr><tr><td>784</td><td>[269, 307, … 327]</td><td>null</td></tr><tr><td>384</td><td>[272, 355, … 286]</td><td>null</td></tr><tr><td>416</td><td>[972]</td><td>[724, 250, … 153]</td></tr><tr><td>856</td><td>[258, 750, … 272]</td><td>null</td></tr><tr><td>480</td><td>[190, 183, … 98]</td><td>null</td></tr><tr><td>280</td><td>[631, 1, … 233]</td><td>null</td></tr><tr><td>752</td><td>[272, 748, … 902]</td><td>null</td></tr><tr><td>840</td><td>[479, 152, … 432]</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>335</td><td>[245, 269, … 340]</td><td>null</td></tr><tr><td>39</td><td>[315, 352, … 319]</td><td>null</td></tr><tr><td>383</td><td>[505, 464, … 200]</td><td>null</td></tr><tr><td>423</td><td>[744, 237, … 508]</td><td>null</td></tr><tr><td>767</td><td>[1068, 486, … 180]</td><td>null</td></tr><tr><td>119</td><td>[451, 995]</td><td>[392, 1153, … 257]</td></tr><tr><td>831</td><td>[96, 591, … 690]</td><td>null</td></tr><tr><td>223</td><td>[274, 969, … 546]</td><td>null</td></tr><tr><td>183</td><td>[405, 227, … 739]</td><td>null</td></tr><tr><td>903</td><td>[182, 276, … 81]</td><td>[100, 318, … 50]</td></tr><tr><td>191</td><td>[302, 286, … 315]</td><td>null</td></tr><tr><td>279</td><td>[1498, 238, … 7]</td><td>[154, 68, … 901]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (126, 3)\n",
       "┌─────────┬───────────────────┬──────────────────┐\n",
       "│ user_id ┆ test_item_ids     ┆ train_item_ids   │\n",
       "│ ---     ┆ ---               ┆ ---              │\n",
       "│ i64     ┆ list[i64]         ┆ list[i64]        │\n",
       "╞═════════╪═══════════════════╪══════════════════╡\n",
       "│ 488     ┆ [510, 748, … 705] ┆ null             │\n",
       "│ 704     ┆ [205, 354, … 134] ┆ null             │\n",
       "│ 776     ┆ [168, 127, … 523] ┆ null             │\n",
       "│ 720     ┆ [258, 304, … 242] ┆ null             │\n",
       "│ …       ┆ …                 ┆ …                │\n",
       "│ 183     ┆ [405, 227, … 739] ┆ null             │\n",
       "│ 903     ┆ [182, 276, … 81]  ┆ [100, 318, … 50] │\n",
       "│ 191     ┆ [302, 286, … 315] ┆ null             │\n",
       "│ 279     ┆ [1498, 238, … 7]  ┆ [154, 68, … 901] │\n",
       "└─────────┴───────────────────┴──────────────────┘"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_items = train_df.groupby('user_id').agg(\n",
    "    pl.col('item_id').alias('train_item_ids')\n",
    ")\n",
    "test_user_items = test_df.groupby('user_id').agg(\n",
    "    pl.col('item_id').alias('test_item_ids')\n",
    ")\n",
    "grouped_user_items = test_user_items.join(train_user_items, 'user_id', 'left')\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ffa80a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.16179532508348066\n"
     ]
    }
   ],
   "source": [
    "# строим индекс объектов\n",
    "index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "index.add(item_embs)\n",
    "    \n",
    "for user_id, test_ids, train_ids in grouped_user_items.rows():\n",
    "    if train_ids:\n",
    "        # используем инференс модели с помощью эмбеддинга пользователя\n",
    "        user_history = train_ids\n",
    "        \n",
    "        y_rel = test_ids\n",
    "        y_rec = [item_id for item_id in recs[user_id] if item_id not in user_history]\n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "    else:\n",
    "        # используем итеративный эмбеддинг по объектам\n",
    "        user_emb = np.zeros(item_embs.shape[1])\n",
    "        user_history = set()\n",
    "        for i, item_ind in enumerate(test_ids[:-1]):\n",
    "            if item_ind < len(item_embs):\n",
    "                user_emb += item_embs[item_ind]\n",
    "                \n",
    "            user_history.add(item_ind)    \n",
    "            y_rel = [test_ids[i + 1]]\n",
    "            y_rec = [\n",
    "                item_id \n",
    "                for item_id in index.search(user_emb[np.newaxis, :], TOP_K * 3)[1][0]\n",
    "                if item_id not in user_history\n",
    "            ]\n",
    "    \n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83a1a4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.060228452751817235,\n",
       " 'warm': 0.20689655172413793,\n",
       " 'cold': 0.055674518201284794}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba7267",
   "metadata": {},
   "source": [
    "## Валидация по событиям\n",
    "\n",
    "В такой валидации мы рассматриваем для пользователя все взаимодействия, отсортированные по времени и оставляем последние N взаимодействия в качестве валидации, а все что раньше – для тренировки. У этого способа есть такая же проблема с тем, что при обучении могут сказываться дата-лики, однако в этом случае мы учитываем как холодных, так и теплых пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81b23fdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (911, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>train_item_ids</th><th>test_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>328</td><td>[302, 286, … 316]</td><td>[1313]</td></tr><tr><td>224</td><td>[300, 313, … 570]</td><td>[239]</td></tr><tr><td>112</td><td>[750, 887, … 315]</td><td>[346]</td></tr><tr><td>152</td><td>[286, 283, … 313]</td><td>[272]</td></tr><tr><td>296</td><td>[242, 292, … 204]</td><td>[209]</td></tr><tr><td>496</td><td>[268, 181, … 217]</td><td>[87]</td></tr><tr><td>544</td><td>[286, 346, … 749]</td><td>[300]</td></tr><tr><td>824</td><td>[268, 259, 322]</td><td>[325]</td></tr><tr><td>248</td><td>[343, 324, … 249]</td><td>[405]</td></tr><tr><td>48</td><td>[690, 306, … 98]</td><td>[302]</td></tr><tr><td>272</td><td>[288, 127, … 514]</td><td>[193]</td></tr><tr><td>696</td><td>[305, 315, … 124]</td><td>[285]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>815</td><td>[50, 9, … 528]</td><td>[427]</td></tr><tr><td>471</td><td>[878, 95, … 94]</td><td>[102]</td></tr><tr><td>567</td><td>[606, 175, … 293]</td><td>[248]</td></tr><tr><td>447</td><td>[258, 300, … 55]</td><td>[156]</td></tr><tr><td>87</td><td>[135, 523, … 87]</td><td>[1189]</td></tr><tr><td>759</td><td>[300, 258, … 471]</td><td>[281]</td></tr><tr><td>615</td><td>[302, 269, … 629]</td><td>[732]</td></tr><tr><td>279</td><td>[321, 408, … 1059]</td><td>[778]</td></tr><tr><td>511</td><td>[300, 346, … 1527]</td><td>[294]</td></tr><tr><td>271</td><td>[346, 269, … 257]</td><td>[248]</td></tr><tr><td>591</td><td>[286, 306, … 4]</td><td>[856]</td></tr><tr><td>663</td><td>[272, 315, … 655]</td><td>[187]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (911, 3)\n",
       "┌─────────┬────────────────────┬───────────────┐\n",
       "│ user_id ┆ train_item_ids     ┆ test_item_ids │\n",
       "│ ---     ┆ ---                ┆ ---           │\n",
       "│ i64     ┆ list[i64]          ┆ list[i64]     │\n",
       "╞═════════╪════════════════════╪═══════════════╡\n",
       "│ 328     ┆ [302, 286, … 316]  ┆ [1313]        │\n",
       "│ 224     ┆ [300, 313, … 570]  ┆ [239]         │\n",
       "│ 112     ┆ [750, 887, … 315]  ┆ [346]         │\n",
       "│ 152     ┆ [286, 283, … 313]  ┆ [272]         │\n",
       "│ …       ┆ …                  ┆ …             │\n",
       "│ 511     ┆ [300, 346, … 1527] ┆ [294]         │\n",
       "│ 271     ┆ [346, 269, … 257]  ┆ [248]         │\n",
       "│ 591     ┆ [286, 306, … 4]    ┆ [856]         │\n",
       "│ 663     ┆ [272, 315, … 655]  ┆ [187]         │\n",
       "└─────────┴────────────────────┴───────────────┘"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_user_items = (\n",
    "    ratings\n",
    "    .sort('timestamp')\n",
    "    .groupby('user_id')\n",
    "    .agg([\n",
    "        pl.col('item_id').apply(lambda x: x[:-1]).alias('train_item_ids'),\n",
    "        pl.col('item_id').apply(lambda x: [x[-1]]).alias('test_item_ids')\n",
    "    ])\n",
    ")\n",
    "\n",
    "# sanity check\n",
    "assert len(\n",
    "    grouped_user_items\n",
    "    .filter(pl.col('test_item_ids').apply(lambda x: len(x) == 0))\n",
    ") == 0\n",
    "\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bfa4b783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6fb49e12b74ceda519b00c349fafd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = (\n",
    "    grouped_user_items\n",
    "    .select('user_id', 'train_item_ids')\n",
    "    .explode('train_item_ids')\n",
    "    .rename({'train_item_ids': 'item_id'})\n",
    ")\n",
    "\n",
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86e96425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.09330406147091108\n"
     ]
    }
   ],
   "source": [
    "hitrate_list = []\n",
    "for user_id, user_history, y_rel in grouped_user_items.rows():\n",
    "    y_rec = [\n",
    "        item_id\n",
    "        for item_id in recs[user_id]\n",
    "        if item_id not in user_history\n",
    "    ]\n",
    "    hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2794ee74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.07352941176470588,\n",
       " 'warm': 0.2318840579710145,\n",
       " 'cold': 0.06709829311359623}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fcf2e9",
   "metadata": {},
   "source": [
    "## Approximate KNN с помощью Qdrant\n",
    "\n",
    "В отдельном процессе нужно запустить серверную часть [qdrant](https://qdrant.tech/) следующей командой:\n",
    "\n",
    "`docker run -p 6333:6333 qdrant/qdrant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a6394cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "client.recreate_collection(\n",
    "    collection_name=\"item_embs\",\n",
    "    # задаем размерность векторов и метрику дистанции\n",
    "    vectors_config=VectorParams(size=item_embs.shape[1], distance=Distance.DOT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84ae462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operation_info = client.upsert(\n",
    "    collection_name=\"item_embs\",\n",
    "    wait=True,\n",
    "    points=[\n",
    "        PointStruct(id=(item_id + 1), vector=item_emb.tolist())\n",
    "        for item_id, item_emb in enumerate(item_embs[1:])\n",
    "    ]\n",
    ")\n",
    "operation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d4c9326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=222, version=0, score=0.33572915, payload={}, vector=None),\n",
       " ScoredPoint(id=228, version=0, score=0.31374466, payload={}, vector=None),\n",
       " ScoredPoint(id=202, version=0, score=0.30496037, payload={}, vector=None),\n",
       " ScoredPoint(id=227, version=0, score=0.28887057, payload={}, vector=None),\n",
       " ScoredPoint(id=405, version=0, score=0.2654244, payload={}, vector=None),\n",
       " ScoredPoint(id=230, version=0, score=0.23762143, payload={}, vector=None),\n",
       " ScoredPoint(id=229, version=0, score=0.18529022, payload={}, vector=None),\n",
       " ScoredPoint(id=196, version=0, score=0.18061997, payload={}, vector=None),\n",
       " ScoredPoint(id=380, version=0, score=0.17917344, payload={}, vector=None),\n",
       " ScoredPoint(id=151, version=0, score=0.16398694, payload={}, vector=None)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 183\n",
    "search_result = client.search(\n",
    "    collection_name=\"item_embs\",\n",
    "    query_vector=user_embs[user_id].tolist(),\n",
    "    limit=TOP_K\n",
    ")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5af269c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rel = holdout_set.filter(pl.col('user_id') == user_id)['item_id'].to_list()\n",
    "y_rec = [s.id for s in search_result]\n",
    "user_hitrate(y_rel, y_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9cc743",
   "metadata": {},
   "source": [
    "## watched filter с разреженной матрицей\n",
    "\n",
    "Для работы с redis нужно запустить docker контейнер следующей командой:\n",
    "\n",
    "`docker run --rm -p 6379:6379 redis/redis-stack-server:latest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7887ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "n_interactions = 10_000\n",
    "n_users = 10_000\n",
    "n_items = 1_000_000\n",
    "\n",
    "# wanna generate sparse matrix\n",
    "assert n_interactions <= n_users * n_items / 100\n",
    "\n",
    "interactions = set()\n",
    "\n",
    "for _ in range(n_interactions):\n",
    "    while True:\n",
    "        user = np.random.choice(n_users)\n",
    "        item = np.random.choice(n_items)\n",
    "\n",
    "        if (item, user) not in interactions:\n",
    "            interactions.add((item, user))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03b2ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(host='localhost', db=0)\n",
    "used_memory_before = r.info('memory')['used_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d321b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, user in interactions:\n",
    "    r.set(f'{item}-{user}', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7253ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.info('memory')['used_memory'] - used_memory_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffdd76a",
   "metadata": {},
   "source": [
    "Использовали ~500Кб памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e39a79cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4972 ± 0.3755 ms\n"
     ]
    }
   ],
   "source": [
    "for item, user in interactions:\n",
    "    assert r.get(f'{item}-{user}') is not None\n",
    "    \n",
    "get_time_elapsed = []\n",
    "for _ in range(n_interactions):\n",
    "    user = np.random.choice(n_users)\n",
    "    item = np.random.choice(n_items)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    get_result = r.get(f'{item}-{user}')\n",
    "    get_time_elapsed.append((time.time() - t_start) * 1_000)\n",
    "    \n",
    "    if (item, user) in interactions:\n",
    "        assert get_result is not None\n",
    "        \n",
    "print(f'{np.mean(get_time_elapsed):.4f} ± {np.std(get_time_elapsed):.4f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed360e2",
   "metadata": {},
   "source": [
    "## Watched filter с помощью redis\n",
    "\n",
    "https://redis-py.readthedocs.io/en/stable/redismodules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca07f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(db=1)\n",
    "used_memory_before = r.info('memory')['used_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1ddb495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# создадим БД watched_filter, которая будет расчитана на предопределенное число интеракций\n",
    "# и делать в среднем 0.1% (вероятность делится на 100) ложноположительных срабатываний\n",
    "r.bf().reserve('watched_filter', 0.001, n_interactions)\n",
    "\n",
    "for item, user in interactions:\n",
    "    r.bf().add('watched_filter', f'{item}-{user}')\n",
    "    \n",
    "for item, user in interactions:\n",
    "    assert r.bf().exists('watched_filter', f'{item}-{user}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f360deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20032"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.info('memory')['used_memory'] - used_memory_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24beb5b",
   "metadata": {},
   "source": [
    "Для хранения используем в ~ 30 раз меньше памяти\n",
    "\n",
    "Теперь проверим, изменилось ли время работы и сколько ложноположительных срабатываний произошло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b36ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество ложноположительных ошибок: 5\n",
      "0.5422 ± 0.4093 ms\n"
     ]
    }
   ],
   "source": [
    "num_errors = 0\n",
    "get_time_elapsed = []\n",
    "\n",
    "for _ in range(n_interactions):\n",
    "    user = np.random.choice(n_users)\n",
    "    item = np.random.choice(n_items)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    get_result = r.bf().exists('watched_filter', f'{item}-{user}')\n",
    "    get_time_elapsed.append((time.time() - t_start) * 1_000)\n",
    "    \n",
    "    if (item, user) in interactions and get_result == 0:\n",
    "        raise Exception('У bloom filter не бывает ложноотрицательных срабатываний')\n",
    "    if (item, user) not in interactions and get_result == 1:\n",
    "        num_errors += 1\n",
    "        \n",
    "print(f'Количество ложноположительных ошибок: {num_errors}')\n",
    "print(f'{np.mean(get_time_elapsed):.4f} ± {np.std(get_time_elapsed):.4f} ms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
